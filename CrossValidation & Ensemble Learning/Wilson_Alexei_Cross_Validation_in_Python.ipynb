{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMoPlBdz8sF4"
      },
      "source": [
        "# Improve Your Model Performance using Cross Validation\n",
        "\n",
        "If you run your machine learning model several times, even with the same configuration, you may notice that your model performance may go up and down. Why would that happen? Since machine learning models try to approximate the data - there is always __uncertainty__ in there.\n",
        "\n",
        "We want to limit the __uncertainty__ in our models, so that _the model can produce consistent results on unseen data_. In other words, if the model uncertainty is too high, the model may produce unreliable results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGyqCnF-_3H"
      },
      "source": [
        "## Why do models lose stability?\n",
        "Let’s understand this using the below snapshot illustrating the fit of various models:\n",
        "\n",
        "![Model Stability](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/15.png)\n",
        "\n",
        "Here, we are trying to find the relationship between size and price. To achieve this, we have taken the following steps:\n",
        "\n",
        "1. In the first plot, you can observe high error (model fitting loosely to the data) - it is an example of “Underfitting”.\n",
        "The first plot has a high error from training data points.\n",
        "2. In the second plot, we just found the right relationship between price and size, i.e., low training error and generalization of the relationship.\n",
        "3. In the third plot, we found a relationship which has almost zero training error. This is because the relationship is developed by considering each deviation in the data point (including noise), i.e., the model is too sensitive and captures random patterns which are present only in the current dataset. This is an example of “Overfitting”.\n",
        "\n",
        "A common practice in data science competitions is to iterate over various models to find a better performing model. However, it becomes difficult to distinguish whether this improvement in score is coming because we are capturing the relationship better, or we are just over-fitting the data. To find the right answer for this question, we use validation techniques. This method helps us in achieving more generalized relationships.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM-9wxrSAuv2"
      },
      "source": [
        "## Before Cross Validation\n",
        "\n",
        "So far, in all but one tutorials in this class, we have been using the traditional train-test split method for validation purposes. This method is called the __(_fixed_) hold-out method__. In this method, a fixed portion of the data (e.g. _20%_) is reserved for evaluation purposes.\n",
        "\n",
        "Refresh your memory with the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gty6yjp8rft"
      },
      "source": [
        "# import the required packages\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abBLqfdD8f6Q",
        "outputId": "2b0a81ae-d74b-4e93-8b5f-bf7d973d0276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the wine dataset\n",
        "my_data = load_breast_cancer()\n",
        "my_data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgE4BDXFCM3P",
        "outputId": "0edce487-2c0b-426c-fe7c-fe2c64203066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "my_df = pd.DataFrame(my_data.data, columns=my_data.feature_names)\n",
        "my_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08b022ed-5748-411d-9112-82d4e06a38c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08b022ed-5748-411d-9112-82d4e06a38c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08b022ed-5748-411d-9112-82d4e06a38c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08b022ed-5748-411d-9112-82d4e06a38c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ZHhVXdCjUb",
        "outputId": "5152c987-43d4-4f7d-8ae0-814b0b9ec754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "my_df['label'] = my_data.target\n",
        "my_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                 0.07871  ...          17.33           184.60      2019.0   \n",
              "1                 0.05667  ...          23.41           158.80      1956.0   \n",
              "2                 0.05999  ...          25.53           152.50      1709.0   \n",
              "3                 0.09744  ...          26.50            98.87       567.7   \n",
              "4                 0.05883  ...          16.67           152.20      1575.0   \n",
              "\n",
              "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   worst symmetry  worst fractal dimension  label  \n",
              "0          0.4601                  0.11890      0  \n",
              "1          0.2750                  0.08902      0  \n",
              "2          0.3613                  0.08758      0  \n",
              "3          0.6638                  0.17300      0  \n",
              "4          0.2364                  0.07678      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-238480bd-64a3-4e3e-9735-bb778ce24731\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-238480bd-64a3-4e3e-9735-bb778ce24731')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-238480bd-64a3-4e3e-9735-bb778ce24731 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-238480bd-64a3-4e3e-9735-bb778ce24731');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ozuEkb4Ctad"
      },
      "source": [
        "# split the data into train/test\n",
        "# test takes up 20% of the data\n",
        "X_train, X_test,y_train, y_test\\\n",
        "    = train_test_split(my_data.data, my_data.target, test_size=0.2, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBebu-Z_DJWF",
        "outputId": "0097e18c-5f2f-4f63-fe58-85f8e2dbc1d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((455, 30), (455,), (114, 30), (114,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYzNjeLWEane"
      },
      "source": [
        "We discussed sometimes we might want to reserve a portion of the data for model optimization purposes - that portion of the data is called the validation set. So that method is called the _three-way hold-out method_.\n",
        "\n",
        "![three way hold out](https://i.stack.imgur.com/pXAfX.png)\n",
        "\n",
        "We can also do that with `train_test_split()`. Say we want to reserve `20%` for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GpzAiCUDZun"
      },
      "source": [
        "X_train, X_val, y_train, y_val\\\n",
        "   = train_test_split(X_train, y_train, test_size=0.25, random_state=2020) # 0.25 x 0.8 = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSxXcdsqFwT_",
        "outputId": "ddaf8fb9-47fe-44e2-8d15-ac25207d99af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((341, 30), (114, 30), (341,), (114,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbqy7dtGGgTC"
      },
      "source": [
        "Now we can try to fit the model multiple times to observe the variance in model performances with the __hold out method__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDuMwoOAGCrz",
        "outputId": "538200fe-2271-4fd2-a74c-800abc610383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = SVC(C=1.0)\n",
        "for i in range(10):\n",
        "  fit = clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print('Accruracy for ', i, 'th round training: ', round(accuracy_score(y_test, y_pred), 4)) # no variance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accruracy for  0 th round training:  0.8947\n",
            "Accruracy for  1 th round training:  0.8947\n",
            "Accruracy for  2 th round training:  0.8947\n",
            "Accruracy for  3 th round training:  0.8947\n",
            "Accruracy for  4 th round training:  0.8947\n",
            "Accruracy for  5 th round training:  0.8947\n",
            "Accruracy for  6 th round training:  0.8947\n",
            "Accruracy for  7 th round training:  0.8947\n",
            "Accruracy for  8 th round training:  0.8947\n",
            "Accruracy for  9 th round training:  0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h82ts6waHunF"
      },
      "source": [
        "We can observe from above there are no variances in the results - since `sklearn` will always optimize your model within the current configuration.\n",
        "\n",
        "If we want to see some variance, we need to have different training/test sets (with the same 80:20 split). We can do that via the __Repeated Holdout__ method. See the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF2-7VuWxJNV",
        "outputId": "6fde68b6-f080-42f1-ab9e-bd0b94a57ae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10):\n",
        "  # remove `random_state` so we have different training/test sample in every iteration\n",
        "  X_train, X_test,y_train, y_test\\\n",
        "    = train_test_split(my_data.data, my_data.target, test_size=0.2)\n",
        "  fit = clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print('Accruracy for ', i, 'th round training: ', round(accuracy_score(y_test, y_pred), 4)) # some variance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accruracy for  0 th round training:  0.9298\n",
            "Accruracy for  1 th round training:  0.886\n",
            "Accruracy for  2 th round training:  0.8772\n",
            "Accruracy for  3 th round training:  0.9386\n",
            "Accruracy for  4 th round training:  0.9123\n",
            "Accruracy for  5 th round training:  0.8947\n",
            "Accruracy for  6 th round training:  0.9035\n",
            "Accruracy for  7 th round training:  0.9123\n",
            "Accruracy for  8 th round training:  0.9123\n",
            "Accruracy for  9 th round training:  0.886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUVscJpewsU2"
      },
      "source": [
        "Now you can see some bumping ups and downs in the results (variance).\n",
        "\n",
        "So what is wrong with the hold out and the repeated holdout methods? Since you essentially is training your model in one shot, you may get a \"lucky draw' of your data (in which your model outperforms the actual), or even worse, an \"unlucky draw\" (in which your model underperforms the actual). We do not want either situation - we want a __fair estimate__ of the model performance.\n",
        "\n",
        "In other words, you want your model to be exposed to as much data as you can, so the model can learn a comprehensive pattern (not a partial image) from your data. Since we cannot use all the data for training, that is why we need __Cross Validation__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs8sjY0ZAFYL"
      },
      "source": [
        "## What is Cross Validation?\n",
        "Cross Validation is a technique which involves reserving a particular sample of a dataset on which you do not train the model. Later, you test your model on this sample before finalizing it.\n",
        "\n",
        "Here are the steps involved in k-fold cross validation:\n",
        "\n",
        "1. Split your dataset into K (roughly) equal folds, and reserve 1 fold for evaluation/optimization purposes - note these two are related but different;\n",
        "2. Train the model using the remaining (K-1) folds and the reserve sample as the test (validation) set. This will help you in gauging the effectiveness of your model’s performance.\n",
        "\n",
        "If your model delivers a positive result on validation data, go ahead with the current model.\n",
        "\n",
        "Even though k-fold cross validation is the most popular type, do not assume that it is the _only_ cross validation method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIOnBIt7JO6Y"
      },
      "source": [
        "## Common Methods for Cross Validation\n",
        "\n",
        "Cross Validation (CV) is a family of sampling/model evaluation/model optimization methods. In the stats context, it is a sampling method. In the machine learning context, it is widely used for model evaluation and/or model optimization purposes.\n",
        "\n",
        "There is a recommendation that every model needs to go through CV once, either for model evaluation or model optimization purposes.\n",
        "\n",
        "Here is a list of common CV methods:\n",
        "- Leave-One-Out Cross Validation (LOOCV) (_most extreme_)\n",
        "- K-fold Cross Validation (_most popular_)\n",
        "- Repeated K-fold Cross Validation\n",
        "- Stratified K-fold Cross Validation (_best for imblanced data_)\n",
        "- Cross Validation for Time Series (_fairly popular right now_)\n",
        "\n",
        "Let's see how to implement them one by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMj-44tMLkE3"
      },
      "source": [
        "### Leave-One-Out Cross Validation (LOOCV)\n",
        "\n",
        "LOOCV is the most extreme CV method. In every iteration, only __one data point__ is used for testing, the remainder of the data is used for training.\n",
        "\n",
        "Pros:\n",
        "- Model is fit to almost the whole dataset; very little chance of having a \"lucky/unlucky\" draw;\n",
        "\n",
        "Cons:\n",
        "- Training is slow;\n",
        "- Variance in model performances is high.\n",
        "\n",
        "Even though `sklearn` has its own `LeaveOneOut` method, we can essentially use the `KFold()` method for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJMbGZTGNtN",
        "outputId": "ed925147-4dff-40f0-8e00-550c664551ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = my_data.data\n",
        "\n",
        "kf = KFold(n_splits=len(X)) # split the data\n",
        "\n",
        "# look at the first 3 iterations\n",
        "i = 0\n",
        "for train_index, test_index in kf.split(X):\n",
        "  print(\"Training data contains\", len(train_index), \"data points\")\n",
        "  print(\"TEST data contains\", len(test_index), \"data points\")\n",
        "  i += 1\n",
        "  if i > 3:\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data contains 568 data points\n",
            "TEST data contains 1 data points\n",
            "Training data contains 568 data points\n",
            "TEST data contains 1 data points\n",
            "Training data contains 568 data points\n",
            "TEST data contains 1 data points\n",
            "Training data contains 568 data points\n",
            "TEST data contains 1 data points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Avg-k0jOE9w"
      },
      "source": [
        "We can see in every iteration, the training dataset contains $569 - 1 = 568$ instances, and the test set contains $1$ data point.\n",
        "\n",
        "Even though we can implement the LOOCV in `sklearn`, it is not well supported in it. So we will stop here and move on to the next method, K-fold CV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlBKU3pJUJPc"
      },
      "source": [
        "### K-fold Cross Validation\n",
        "\n",
        "This is the most popular method in the context of CV.\n",
        "\n",
        "Pros:\n",
        "- Most balanced method;\n",
        "- Can be used for both model evaluation and optmization purposes\n",
        "\n",
        "Cons:\n",
        "- if dataset is too small and K is too large, model might underfit\n",
        "- if k is too small, model may overfit\n",
        "\n",
        "For __evaluation purposes__, we can simply use the `cross_val_score` method.\n",
        "- it takes the model, features, target, and K as function parameters\n",
        "- by default the returned value is the accuracy score (e.g. classification accuracy for our model)\n",
        "\n",
        "Below code performs a 5-fold CV using the `SVC` model above on our data - you can see five different _accuracy_ scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcCiWrEaOBWd",
        "outputId": "b0d9d7e8-f05f-44a6-be79-3bd80d3fbe51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = my_data.target\n",
        "cross_val_score(clf, X, y, cv=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85087719, 0.89473684, 0.92982456, 0.94736842, 0.9380531 ])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgX8_8ukPNYP",
        "outputId": "d2a69a44-5db2-4b01-b042-e80d09449aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# change k to 3\n",
        "cross_val_score(clf, X, y, cv=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85263158, 0.93157895, 0.94708995])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kevx4sjmaTD-",
        "outputId": "188af61f-f18e-4ea9-f4e6-1f25e383967f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# change k to 10\n",
        "cross_val_score(clf, X, y, cv=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89473684, 0.84210526, 0.89473684, 0.92982456, 0.92982456,\n",
              "       0.92982456, 0.94736842, 0.92982456, 0.92982456, 0.91071429])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qi1S5yPaaQ7"
      },
      "source": [
        "If you want the final score of the model, usually we will use the __average__ across the `k` iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tetH2vZ0aXA2",
        "outputId": "eafff89e-17c5-43ba-bf79-c00509a97b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('final model accuracy:', cross_val_score(clf, X, y, cv=10).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final model accuracy: 0.9138784461152882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV03Cf1ykyEe"
      },
      "source": [
        "You can also test how much the variance is in the results, you can check the _standard deviation_ of the scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEEyfxsLlAWy",
        "outputId": "0aac9390-4ca4-48d3-e385-389990b1944c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('model accuracy variance:', np.std(cross_val_score(clf, X, y, cv=10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy variance: 0.02878745403168186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohqS71-ubCbZ"
      },
      "source": [
        "You can also specify using different metrics. For instance, we may want to focus on the _f1-score_ or the _ROC/AUC_ metric. All supported scoring metrics are listed [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "\n",
        "We can do that using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpaIoGw-a-5j",
        "outputId": "7563dbbc-6d15-4ea5-ebca-f61f243ce281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cross_val_score(clf, X, y, cv=10, scoring='f1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92105263, 0.88311688, 0.91891892, 0.94736842, 0.94736842,\n",
              "       0.94594595, 0.95890411, 0.94594595, 0.94444444, 0.93333333])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC83Busnb-yx",
        "outputId": "b64ac43a-d5dc-4f4f-a345-6d3d0a61cff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cross_val_score(clf, X, y, cv=10, scoring='roc_auc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96753247, 0.95324675, 0.98412698, 0.96957672, 0.98809524,\n",
              "       0.98015873, 0.97883598, 0.96296296, 0.98412698, 0.99047619])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pixwJKlKdJoe"
      },
      "source": [
        "The `cross_val_score` method is a shortcut for model evaluation purposes. The regular method is `KFold` - if we want to use the K-fold CV for model optimization purposes, we can use `KFold`, or specific methods for hyperparameter tuning that we will see next week."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdEIdGfvc0Fv"
      },
      "source": [
        "### Repeated K-fold Cross Validation\n",
        "\n",
        "Repeated K-fold CV is basically conducting the K-Fold cross validation `i` times. See the comparison below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGxs_9JJeylL",
        "outputId": "aa8d8a49-630e-47d7-8cd2-df7b21f4d52c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create some synthetic data for illustration\n",
        "X_data = np.random.randint(5, size=(9, 2))\n",
        "X_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 2],\n",
              "       [0, 0],\n",
              "       [4, 2],\n",
              "       [0, 0],\n",
              "       [2, 3],\n",
              "       [1, 3],\n",
              "       [0, 1],\n",
              "       [2, 3],\n",
              "       [3, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKNg2Y-TgEiA"
      },
      "source": [
        "Regular K-fold CV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hewgn3dWfTBy",
        "outputId": "48bf6c29-0c49-44c3-a7a2-0ab7112e3a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kf = KFold(n_splits=3, random_state=2020, shuffle=True)\n",
        "for train_index, test_index in kf.split(X_data):\n",
        "      print(\"Train:\")\n",
        "      print(X_data[train_index])\n",
        "      print(\"Test:\")\n",
        "      print(X_data[test_index])\n",
        "      print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[4 2]\n",
            " [2 3]\n",
            " [2 3]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [2 3]]\n",
            "Test:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [3 0]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78dI4KwrgH9r"
      },
      "source": [
        "Repeated K-fold CV:\n",
        "Note that between the repeat, the data is variant (not simple repeat, repeat with randomness)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSjOSAxlgCsX",
        "outputId": "408009c2-bbcb-493d-a1ef-5f986a053b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rkf = RepeatedKFold(n_splits=3, n_repeats=5, random_state=2020)\n",
        "for train_index, test_index in rkf.split(X_data):\n",
        "      print(\"Train:\")\n",
        "      print(X_data[train_index])\n",
        "      print(\"Test:\")\n",
        "      print(X_data[test_index])\n",
        "      print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[4 2]\n",
            " [2 3]\n",
            " [2 3]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [2 3]]\n",
            "Test:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [3 0]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[2 3]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [0 0]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "Test:\n",
            "[[3 2]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [2 3]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [3 0]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[3 2]\n",
            " [2 3]\n",
            " [2 3]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [4 2]\n",
            " [2 3]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[0 0]\n",
            " [4 2]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [2 3]]\n",
            "Test:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [3 0]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[4 2]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [2 3]\n",
            " [2 3]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[4 2]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [0 0]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "Test:\n",
            "[[4 2]\n",
            " [2 3]\n",
            " [1 3]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [1 3]]\n",
            "Test:\n",
            "[[0 1]\n",
            " [2 3]\n",
            " [3 0]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSNKDVAmch-q"
      },
      "source": [
        "### Stratified K-fold Cross Validation\n",
        "\n",
        "Stratified K-fold CV is particularly useful when the data is imbalanced. See below code for the use of the `StratifiedKFold` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxo_6IWicD0K",
        "outputId": "ec265690-cbe4-481e-d04a-8a102d750b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "# X is the feature set and y is the target\n",
        "for train_index, val_index in skf.split(X,y):\n",
        "    print(\"Train:\", train_index, \"Validation:\", val_index)\n",
        "    X_train, X_test = X[train_index], X[val_index]\n",
        "    y_train, y_test = y[train_index], y[val_index]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: [ 53  54  56  57  62  64  65  70  72  73  75  77  78  82  83  85  86  87\n",
            "  91  94  95  99 100 105 108 117 118 119 121 122 126 127 129 131 132 134\n",
            " 135 138 141 146 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
            " 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n",
            " 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221\n",
            " 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239\n",
            " 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257\n",
            " 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275\n",
            " 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293\n",
            " 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311\n",
            " 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329\n",
            " 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347\n",
            " 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365\n",
            " 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383\n",
            " 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
            " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
            " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
            " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
            " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
            " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
            " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
            " 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527\n",
            " 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545\n",
            " 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563\n",
            " 564 565 566 567 568] Validation: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  55\n",
            "  58  59  60  61  63  66  67  68  69  71  74  76  79  80  81  84  88  89\n",
            "  90  92  93  96  97  98 101 102 103 104 106 107 109 110 111 112 113 114\n",
            " 115 116 120 123 124 125 128 130 133 136 137 139 140 142 143 144 145 147\n",
            " 148 149 150 151 152 153]\n",
            "Train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  55\n",
            "  58  59  60  61  63  66  67  68  69  71  74  76  79  80  81  84  88  89\n",
            "  90  92  93  96  97  98 101 102 103 104 106 107 109 110 111 112 113 114\n",
            " 115 116 120 123 124 125 128 130 133 136 137 139 140 142 143 144 145 147\n",
            " 148 149 150 151 152 153 164 167 168 171 172 177 180 181 182 184 186 190\n",
            " 193 194 196 197 198 199 201 202 203 205 207 210 212 213 214 215 218 219\n",
            " 223 229 230 233 236 237 239 244 250 252 253 254 255 256 257 258 259 260\n",
            " 261 262 263 264 265 272 274 277 280 282 283 287 288 289 290 291 292 293\n",
            " 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311\n",
            " 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329\n",
            " 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347\n",
            " 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365\n",
            " 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383\n",
            " 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
            " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
            " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
            " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
            " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
            " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
            " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
            " 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527\n",
            " 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545\n",
            " 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563\n",
            " 564 565 566 567 568] Validation: [ 53  54  56  57  62  64  65  70  72  73  75  77  78  82  83  85  86  87\n",
            "  91  94  95  99 100 105 108 117 118 119 121 122 126 127 129 131 132 134\n",
            " 135 138 141 146 154 155 156 157 158 159 160 161 162 163 165 166 169 170\n",
            " 173 174 175 176 178 179 183 185 187 188 189 191 192 195 200 204 206 208\n",
            " 209 211 216 217 220 221 222 224 225 226 227 228 231 232 234 235 238 240\n",
            " 241 242 243 245 246 247 248 249 251 266 267 268 269 270 271 273 275 276\n",
            " 278 279 281 284 285 286]\n",
            "Train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 165 166 169 170 173 174 175 176 178 179 183 185 187 188 189 191\n",
            " 192 195 200 204 206 208 209 211 216 217 220 221 222 224 225 226 227 228\n",
            " 231 232 234 235 238 240 241 242 243 245 246 247 248 249 251 255 256 257\n",
            " 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275\n",
            " 276 277 278 279 280 281 282 283 284 285 286 297 300 302 317 321 323 328\n",
            " 329 330 335 337 339 343 351 352 353 365 366 368 369 370 372 373 379 383\n",
            " 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401\n",
            " 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
            " 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
            " 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
            " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
            " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
            " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
            " 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527\n",
            " 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545\n",
            " 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563\n",
            " 564 565 566 567 568] Validation: [164 167 168 171 172 177 180 181 182 184 186 190 193 194 196 197 198 199\n",
            " 201 202 203 205 207 210 212 213 214 215 218 219 223 229 230 233 236 237\n",
            " 239 244 250 252 253 254 287 288 289 290 291 292 293 294 295 296 298 299\n",
            " 301 303 304 305 306 307 308 309 310 311 312 313 314 315 316 318 319 320\n",
            " 322 324 325 326 327 331 332 333 334 336 338 340 341 342 344 345 346 347\n",
            " 348 349 350 354 355 356 357 358 359 360 361 362 363 364 367 371 374 375\n",
            " 376 377 378 380 381 382]\n",
            "Train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 266 267 268 269 270 271 273 275 276 278 279 281 284 285 286\n",
            " 287 288 289 290 291 292 293 294 295 296 298 299 301 303 304 305 306 307\n",
            " 308 309 310 311 312 313 314 315 316 318 319 320 322 324 325 326 327 331\n",
            " 332 333 334 336 338 340 341 342 344 345 346 347 348 349 350 354 355 356\n",
            " 357 358 359 360 361 362 363 364 367 371 374 375 376 377 378 380 381 382\n",
            " 389 392 393 400 408 414 417 430 432 433 435 441 444 446 449 451 460 461\n",
            " 468 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
            " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
            " 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527\n",
            " 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545\n",
            " 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563\n",
            " 564 565 566 567 568] Validation: [255 256 257 258 259 260 261 262 263 264 265 272 274 277 280 282 283 297\n",
            " 300 302 317 321 323 328 329 330 335 337 339 343 351 352 353 365 366 368\n",
            " 369 370 372 373 379 383 384 385 386 387 388 390 391 394 395 396 397 398\n",
            " 399 401 402 403 404 405 406 407 409 410 411 412 413 415 416 418 419 420\n",
            " 421 422 423 424 425 426 427 428 429 431 434 436 437 438 439 440 442 443\n",
            " 445 447 448 450 452 453 454 455 456 457 458 459 462 463 464 465 466 467\n",
            " 469 470 471 472 473 474]\n",
            "Train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 390 391 394 395 396 397 398\n",
            " 399 401 402 403 404 405 406 407 409 410 411 412 413 415 416 418 419 420\n",
            " 421 422 423 424 425 426 427 428 429 431 434 436 437 438 439 440 442 443\n",
            " 445 447 448 450 452 453 454 455 456 457 458 459 462 463 464 465 466 467\n",
            " 469 470 471 472 473 474] Validation: [389 392 393 400 408 414 417 430 432 433 435 441 444 446 449 451 460 461\n",
            " 468 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491\n",
            " 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509\n",
            " 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527\n",
            " 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545\n",
            " 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563\n",
            " 564 565 566 567 568]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQgLrZ3ChwxS"
      },
      "source": [
        "As said above, for model evaluation purposes, we can simply use the `cross_val_score` function. In the `cross_val_score` function, if the `cv` value is _integer_, the model (e.g. `clf`) is a classifier, and `y` is _categorical_ (e.g. _binary_ in this case),  `StratifiedKFold` is used. In all other cases, `KFold` is used. In short, `cross_val_score` by default apply stratified K-fold CV for classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_14GHy2yi2ju"
      },
      "source": [
        "### Cross Validation for Time Series\n",
        "\n",
        "Time series data is very special - since the time sequence is implied in the data. Thus, splitting a time-series dataset randomly does not work because the time section of your data will be messed up. For a time series forecasting problem, we perform cross validation in the forward chaining manner.\n",
        "\n",
        "```\n",
        "fold 1: training [1], test [2]\n",
        "fold 2: training [1 2], test [3]\n",
        "fold 3: training [1 2 3], test [4]\n",
        "fold 4: training [1 2 3 4], test [5]\n",
        "fold 5: training [1 2 3 4 5], test [6]\n",
        ".\n",
        ".\n",
        ".\n",
        "fold n: training [1 2 3 ….. n-1], test [n]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZTrRe-Jiy66",
        "outputId": "299386ce-00c5-4e98-8f6b-4c7a4b87b683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "for train_index, test_index in tscv.split(X_data):\n",
        "      print(\"Train:\")\n",
        "      print(X_data[train_index])\n",
        "      print(\"Test:\")\n",
        "      print(X_data[test_index])\n",
        "      print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [4 2]]\n",
            "Test:\n",
            "[[0 0]\n",
            " [2 3]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]]\n",
            "Test:\n",
            "[[1 3]\n",
            " [0 1]]\n",
            "\n",
            "\n",
            "Train:\n",
            "[[3 2]\n",
            " [0 0]\n",
            " [4 2]\n",
            " [0 0]\n",
            " [2 3]\n",
            " [1 3]\n",
            " [0 1]]\n",
            "Test:\n",
            "[[2 3]\n",
            " [3 0]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kojjoc4ej96l"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this tutorial, we discussed the importance of cross validation in machine learning models, in particular we focused on the __model evaluation__ use of CV. Thus, you should be comfortable using the `cross_val_score` function in your model evaluation phase.\n",
        "\n",
        "We also surveyed the most popular CV methods - `sklearn` support most of them natively. In other projects, you may want to use other CV methods.\n",
        "\n",
        "In next week's tutorial, we will use CV for another important purpose: model optimization. Till then, try CV on your own to evaluate your models."
      ]
    }
  ]
}